# -*- coding: utf-8 -*-
"""Predictor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wy6sj_pwFDr3ET8Yw5hY0sq7exGgWT66
"""

import numpy as np
from imblearn.under_sampling import NeighbourhoodCleaningRule
import pandas

import keras
from keras.models import Sequential
from keras.layers import Dense

from keras.models import Sequential
from keras.layers import Dense
from keras.utils.np_utils import to_categorical
from sklearn.utils import resample
import tensorflow as tf

from keras.layers import Dense
# from imblearn.under_sampling import NeighbourhoodCleaningRule
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

import matplotlib.pyplot as plt
import lime.lime_tabular

# Load dataset
dataset = pandas.read_csv("./Data/Supplementary_Table_S1.csv", ";")
print("Dataset imported")

x = dataset.iloc[:, 1:640]
#print(x)
# print(x)
y = dataset['Class']
y = to_categorical(y)
#print(y)

clf = RandomForestClassifier(n_estimators=300, max_depth=9,
                             random_state=0)
clf.fit(x, y)
clf.feature_importances_
model = SelectFromModel(clf, prefit=True)
feature_idx = model.get_support()
feature_name = x.columns[feature_idx]
x = model.transform(x)
#print(list(x[0]))
print(feature_name)

ncr = NeighbourhoodCleaningRule()
x_resampled, y_resampled = ncr.fit_resample(x, y)
y_resampled = to_categorical(y_resampled)

X_train, X_test, y_train, y_test = train_test_split(x_resampled, y_resampled, test_size=0.2, random_state=1)

print(x_resampled)
print("Hello")
print(y_resampled)

# Optimization Algorithm
opt = tf.keras.optimizers.RMSprop(learning_rate=0.00014, rho=0.9, epsilon=None, decay=0.0)

# Multi Layer Perceptron Model
model = Sequential()
model.add(Dense(128, input_dim=193, activation='relu'))
keras.layers.AlphaDropout(0.3, noise_shape=None, seed=None)

model.add(Dense(128, activation='relu'))
keras.layers.AlphaDropout(0.3, noise_shape=None, seed=None)

model.add(Dense(128, activation='relu'))
keras.layers.AlphaDropout(0.3, noise_shape=None, seed=None)

model.add(Dense(128, activation='relu'))
keras.layers.AlphaDropout(0.3, noise_shape=None, seed=None)

model.add(Dense(128, activation='relu'))
keras.layers.AlphaDropout(0.3, noise_shape=None, seed=None)

model.add(Dense(128, activation='relu'))
keras.layers.AlphaDropout(0.3, noise_shape=None, seed=None)

model.add(Dense(2, activation='sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer=opt,
              metrics=['accuracy'])

# Estimator

history = model.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test))
#model.load_weights('./checkpoints/a')
#score = model.evaluate(x_resampled, y_resampled)
#print(score)

print(history.history.keys())

# yhat = model.predict(X_test)
# print("predictions")
# print(yhat)
# classes = np.argmax(yhat, axis = 1)

# acc = accuracy_score(y_test, classes)
# print('Accuracy: %.3f' % acc)

loss_train = history.history['loss']
loss_val = history.history['val_loss']
epochs = range(0,200)
plt.plot(epochs, loss_train, 'g', label='Training loss')
plt.plot(epochs, loss_val, 'b', label='validation loss')
plt.title('Training and Validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

loss_train = history.history['accuracy']
loss_val = history.history['val_accuracy']
epochs = range(0,200)
plt.plot(epochs, loss_train, 'g', label='Training accuracy')
plt.plot(epochs, loss_val, 'b', label='validation accuracy')
plt.title('Training and Validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

mypred = model.predict(X_test)
for row in mypred:
    print(row[0] + row[1])

explainer = lime.lime_tabular.LimeTabularExplainer(X_train, feature_names=list(feature_name), class_names=[0, 1], mode='classification')
# added top_labels=1
# exp = explainer.explain_instance(X_test[2], model.predict, num_features=10, top_labels=2)

# myMap = exp.as_map()
# print(myMap)

print(X_train.shape)

for i in range(0, 200):
    print(i)
    exp = explainer.explain_instance(X_test[i], model.predict, num_features=50)
    fig = exp.as_pyplot_figure()

    fig.set_size_inches((25, 25), forward=False)
    name = "LIME_preds2\\" + str(i) + ".png" 
    fig.savefig(name, dpi=500)

# exp = explainer.explain_instance(X_test[2], model.predict, num_features=50)
# exp.as_pyplot_figure()
# plt.show()
#print(y_test)
#print(yhat)

# save model for future use
#model.save_weights('./checkpoints/a')

# Predictor
# f = np.expand_dims(f, axis=0)
#f = ["aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA"]
#preds = model.predict(f)
#model.predict_classes(f, batch_size=1, verbose=1)

# Print the Results
#print(preds)
# print(pp)
